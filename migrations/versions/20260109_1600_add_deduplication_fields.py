"""add_deduplication_fields

Revision ID: c4f5d6e7f8g9
Revises: ab7e7df9f1d8
Create Date: 2026-01-09 16:00:00.000000

FASE 2A: Campos de deduplicación para detectar y gestionar documentos duplicados.
"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql


# revision identifiers, used by Alembic.
revision = 'c4f5d6e7f8g9'
down_revision = 'ab7e7df9f1d8'
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('documents', schema=None) as batch_op:
        # Hash del contenido textual normalizado (deduplicación semántica)
        batch_op.add_column(sa.Column(
            'content_hash',
            sa.String(length=64),
            nullable=True,
            comment='SHA256 del texto normalizado extraído (detecta contenido duplicado entre formatos)'
        ))
        
        # Embedding del documento completo (para comparación semántica)
        batch_op.add_column(sa.Column(
            'document_embedding',
            sa.JSON(),
            nullable=True,
            comment='Embedding del documento completo (vector) para comparación de similaridad'
        ))
        
        # Flag de duplicado
        batch_op.add_column(sa.Column(
            'is_duplicate',
            sa.Boolean(),
            server_default='false',
            nullable=False,
            comment='Indica si este documento es un duplicado de otro'
        ))
        
        # Referencia al documento original
        batch_op.add_column(sa.Column(
            'duplicate_of_document_id',
            sa.String(length=36),  # UUID = 36 chars
            nullable=True,
            comment='ID del documento original del que este es duplicado'
        ))
        
        # Agregar FK constraint con nombre explícito (requerido por SQLite)
        batch_op.create_foreign_key(
            'fk_duplicate_of_document_id',
            'documents',
            ['duplicate_of_document_id'],
            ['document_id']
        )
        
        # Score de similaridad
        batch_op.add_column(sa.Column(
            'duplicate_similarity',
            sa.Float(),
            nullable=True,
            comment='Score de similaridad con el documento original (0.0=diferente, 1.0=idéntico)'
        ))
        
        # Acción del abogado
        batch_op.add_column(sa.Column(
            'duplicate_action',
            sa.String(length=20),
            nullable=True,
            comment='Acción del abogado: pending, keep_both, mark_duplicate, exclude_from_analysis'
        ))
        
        # Auditoría de decisión del abogado (cadena de custodia legal)
        batch_op.add_column(sa.Column(
            'duplicate_action_at',
            sa.DateTime(timezone=True),
            nullable=True,
            comment='Timestamp de la decisión del abogado sobre duplicado'
        ))
        
        batch_op.add_column(sa.Column(
            'duplicate_action_by',
            sa.String(length=100),
            nullable=True,
            comment='Usuario/email que tomó la decisión sobre duplicado'
        ))
        
        batch_op.add_column(sa.Column(
            'duplicate_action_reason',
            sa.String(length=500),
            nullable=True,
            comment='Razón de la decisión (auditoría legal)'
        ))
        
        # Índices para optimizar búsquedas
        batch_op.create_index(batch_op.f('ix_documents_content_hash'), ['content_hash'], unique=False)
        batch_op.create_index(batch_op.f('ix_documents_duplicate_of_document_id'), ['duplicate_of_document_id'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_documents_duplicate_of_document_id'))
        batch_op.drop_index(batch_op.f('ix_documents_content_hash'))
        batch_op.drop_constraint('fk_duplicate_of_document_id', type_='foreignkey')
        batch_op.drop_column('duplicate_action_reason')
        batch_op.drop_column('duplicate_action_by')
        batch_op.drop_column('duplicate_action_at')
        batch_op.drop_column('duplicate_action')
        batch_op.drop_column('duplicate_similarity')
        batch_op.drop_column('duplicate_of_document_id')
        batch_op.drop_column('is_duplicate')
        batch_op.drop_column('document_embedding')
        batch_op.drop_column('content_hash')

    # ### end Alembic commands ###
