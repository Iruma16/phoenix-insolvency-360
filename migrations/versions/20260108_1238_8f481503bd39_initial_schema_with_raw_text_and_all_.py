"""Initial schema with raw_text and all models

Revision ID: 8f481503bd39
Revises: 
Create Date: 2026-01-08 12:38:20.281853

"""
from alembic import op
import sqlalchemy as sa


# revision identifiers, used by Alembic.
revision = '8f481503bd39'
down_revision = None
branch_labels = None
depends_on = None


def upgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        batch_op.add_column(sa.Column('start_char', sa.Integer(), nullable=False, comment='Offset de inicio en texto original (OBLIGATORIO)'))
        batch_op.add_column(sa.Column('end_char', sa.Integer(), nullable=False, comment='Offset de fin en texto original (OBLIGATORIO)'))
        batch_op.add_column(sa.Column('extraction_method', sa.Enum('PDF_TEXT', 'OCR', 'TABLE', 'DOCX_TEXT', 'TXT', 'UNKNOWN', name='extractionmethod'), nullable=False, comment='Método de extracción del texto (OBLIGATORIO)'))
        batch_op.add_column(sa.Column('page_start', sa.Integer(), nullable=True, comment='Página de inicio (1-indexed) o NULL'))
        batch_op.add_column(sa.Column('page_end', sa.Integer(), nullable=True, comment='Página de fin (1-indexed) o NULL'))
        batch_op.add_column(sa.Column('section_hint', sa.String(length=255), nullable=True, comment='Sección/encabezado inferido o NULL'))
        batch_op.add_column(sa.Column('chunking_strategy', sa.String(length=100), nullable=True, comment='Estrategia de chunking aplicada'))
        batch_op.add_column(sa.Column('content_hash', sa.String(length=64), nullable=True, comment='SHA256 del contenido del chunk (opcional)'))
        batch_op.alter_column('chunk_id',
               existing_type=sa.VARCHAR(length=36),
               type_=sa.String(length=40),
               existing_nullable=False)

    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.add_column(sa.Column('raw_text', sa.Text(), nullable=True, comment='Texto bruto extraído del documento (inmutable, single source of truth)'))
        batch_op.add_column(sa.Column('parsing_status', sa.String(length=20), nullable=True))
        batch_op.add_column(sa.Column('parsing_rejection_reason', sa.String(length=50), nullable=True))
        batch_op.add_column(sa.Column('parsing_metrics', sa.JSON(), nullable=True))
        batch_op.create_index(batch_op.f('ix_documents_parsing_status'), ['parsing_status'], unique=False)

    # ### end Alembic commands ###


def downgrade() -> None:
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('documents', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_documents_parsing_status'))
        batch_op.drop_column('parsing_metrics')
        batch_op.drop_column('parsing_rejection_reason')
        batch_op.drop_column('parsing_status')
        batch_op.drop_column('raw_text')

    with op.batch_alter_table('document_chunks', schema=None) as batch_op:
        batch_op.alter_column('chunk_id',
               existing_type=sa.String(length=40),
               type_=sa.VARCHAR(length=36),
               existing_nullable=False)
        batch_op.drop_column('content_hash')
        batch_op.drop_column('chunking_strategy')
        batch_op.drop_column('section_hint')
        batch_op.drop_column('page_end')
        batch_op.drop_column('page_start')
        batch_op.drop_column('extraction_method')
        batch_op.drop_column('end_char')
        batch_op.drop_column('start_char')

    # ### end Alembic commands ###

